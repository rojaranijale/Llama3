# -*- coding: utf-8 -*-
"""RAG_using_Llama3_12sept_gradio_working.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KEF1e7WuXbkcVlwQ3S63qHGMJ4ZNYVVE
"""

!pip install -q sentence-transformers chromadb langchain-community unstructured openpyxl langchain_huggingface pandas

# 
from huggingface_hub import notebook_login
notebook_login()

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from transformers import AutoTokenizer, pipeline
from langchain_huggingface import HuggingFacePipeline
from langchain.chains import RetrievalQA

from langchain_community.document_loaders import UnstructuredExcelLoader
from langchain.vectorstores import utils as chromautils
loader = UnstructuredExcelLoader("All_ScrapedText_03_06.xlsx")
docs = loader.load()
docs = chromautils.filter_complex_metadata(docs)

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)

docs = text_splitter.split_documents(docs)

modelPath = "mixedbread-ai/mxbai-embed-large-v1"
model_kwargs = {'device':'cuda'}
encode_kwargs = {'normalize_embeddings': True}
embeddings = HuggingFaceEmbeddings(
    model_name=modelPath,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs
)

from langchain.vectorstores import Chroma
db = Chroma.from_documents(docs, embeddings)

retriever = db.as_retriever()

model_id = "meta-llama/Meta-Llama-3-8B-Instruct"

from langchain import PromptTemplate

rag_structured_data_prompt_template = """
You are helping a user select a car part based on relevant information retrieved from an external structured data source and the user's input. Please consider both the retrieved data and the user’s question to provide a well-informed, concise response. Follow these rules:

1. Use the information from the external data source when relevant to the question.
2. Combine the retrieved data with the user's input to offer an accurate and concise answer.
3. If the answer is unclear from the data or user input, suggest that the user check the external data source for more details.
4. Keep the answer concise, limiting your response to 20 sentences maximum.

Here is the retrieved data and relevant context:

{context}

User's Question: {question}

Answer:
"""

PROMPT = PromptTemplate(
 template=rag_structured_data_prompt_template, input_variables=["context", "question"]
)

from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline

llm = HuggingFacePipeline.from_model_id(
    model_id=model_id,
    task="text-generation",
    pipeline_kwargs={"temperature": 0.1, "max_new_tokens": 600},
    device = 0
)

# API endpoint and headers configuration
url = f"https://api.runpod.ai/v2/zacwy61m9tcosg/runsync"
headers = {'Authorization': f'Bearer HOBOYVV732X1NT0JO0J4SWJ0RMKC2LVFK0MRT99H','Content-Type': 'application/json'}

!pip -q install streamlit

from langchain_community.callbacks.streamlit import (
    StreamlitCallbackHandler,
)
import streamlit as st

st_callback = StreamlitCallbackHandler(st.container())

retrievalQA = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True,
    chain_type_kwargs={"prompt": PROMPT}
)

prompt = """Assume you drive a BMW 3 Limousine F30 - 328i – 2011.
Here you see a list of 5 Brake pads and you have to choose one of them.

1.	RIDEX 402B0531 Brake pad set
•	Fitting Position:Rear Axle
•	Suspension:for vehicles without M technology
•	Braking System:for vehicles without Performance brakes
•	Quantity Unit:Axle Set
•	Fitting Position:Rear Axle
•	Wear Warning Contact:prepared for wear indicator
•	Thickness [mm]:17,2
•	Height 1 [mm]:44,1
•	Height 2 [mm]:45,2
•	Width [mm]:123,2
•	WVA Number:25307
•	Price: £ 14,46 price incl. 20% VAT excl. delivery costs
•
2.	RIDEX 402B0828 Brake pad set
•	Braking System:for vehicles with M-performance brakes
•	for brake disc thickness [mm]:30
•	for brake disc diameter [mm]:370
•
•	Braking System:090
•	for brake disc thickness [mm]:30
•	for brake disc diameter [mm]:340
•	Quantity Unit:Axle Set
•	Fitting Position:Front Axle
•	Wear Warning Contact:prepared for wear indicator
•	Material:Low-Metallic
•	Length [mm]:114,5
•	Width [mm]:91,4
•	Thickness 1 [mm]:18,3
•	Weight [kg]:2,315, 2,48
•	Price: £ 33,82 price incl. 20% VAT excl. delivery costs
3.	RIDEX Brake pad set Front axle both sides, prepared for wear indicator, with counterweights
•	Quantity Unit:Axle Set
•	Fitting Position:Front axle both sides
•	Wear Warning Contact:prepared for wear indicator
•	Supplementary Article / Supplementary Info:with counterweights
•	Thickness [mm]:17,7
•	Length [mm]:675
•	Height [mm]:91,2
•	Width [mm]:114,8
•	Brake Type:Disc Brake
•	Quantity per axle:1
•	Price: £ 40,72 (Price per set) price incl. 20% VAT excl. delivery costs
4.	MAPCO 6625HPS Brake pad set
•	Construction Year from:02 / 2012
•	Braking System:for vehicles without Performance brakes
•	Fitting Position:Front Axle
•	Wear Warning Contact:prepared for wear indicator, excl. wear warning contact
•	Brake System:Bosch
•	Thickness [mm]:19,6
•	Height [mm]:69,8
•	Width [mm]:148,2
•	Item number:6625HPS
•	Our price:£ 19,00
•	Manufacturer:MAPCO
•	Price: £ 19,00 price incl. 20% VAT excl. delivery costs
5.	A.B.S. Brake pad set Rear Axle, prepared for wear indicator
•	Fitting Position:Rear Axle
•	Braking System:for vehicles with M-performance brakes
•	for brake disc diameter [mm]:345
•	Quantity Unit:Axle Set
•	Wear Warning Contact:prepared for wear indicator
•	Brake System:BREMBO
•	Height 1 [mm]:88,4
•	Width 1 [mm]:73,6
•	Thickness 1 [mm]:17,2
•	Weight [kg]:1,6
•	Item number:37953
•	Our price:£ 29,58

1.1 prompt: Give me all the specific purchase criteria for the selection of Brake pads (car part)
1.2 prompt: Classify the Brake pads into three price categories, which are also assigned the purchase criteria mentioned.
1.3	prompt: Based on the criteria mentioned, which Brake pads should I buy and why?

"""
response = retrievalQA.invoke(
    {"query": prompt}
)
print(response["result"])

if prompt := st.chat_input():
    st.chat_message("user").write(prompt)
    with st.chat_message("assistant"):
        st_callback = StreamlitCallbackHandler(st.container())
        response = retrievalQA.invoke(
            {"query": prompt}, {"callbacks": [st_callback]}
        )
        st.write(response["result"])

!pip install gradio

import gradio as gr

def query_response(prompt):
    # Simulate LLM or retrieval system response
    response = retrievalQA.invoke({"query": prompt})
    return response["result"]

# Gradio UI with a chatbot-like interface
def chat_interface(messages):
    user_prompt = messages[-1]['content']  # Get user message
    assistant_response = query_response(user_prompt)
    messages.append({"role": "assistant", "content": assistant_response})
    return messages

with gr.Blocks() as demo:
    chat = gr.Chatbot()
    message = gr.Textbox(placeholder="Enter your message here...")
    message.submit(chat_interface, inputs=[chat], outputs=chat)

demo.launch(share=True)



!pip install gradio


import gradio as gr

# Define the chat function
def chat_interface(prompt):
    if not prompt:
        return "Please provide a valid input."

    # Call your RetrievalQA model here
    response = retrievalQA.invoke({"query": prompt})

    # Return the result or a fallback message
    return response["result"] if response["result"] else "No response available."

# Create Gradio interface
demo = gr.Interface(
    fn=chat_interface,
    inputs=gr.Textbox(lines=2, placeholder="Enter your prompt..."),
    outputs=gr.Textbox(),
    title="RAG Chat Interface",
    description="Ask questions and receive responses from the LLM.",
)

# Launch Gradio interface with a public link
demo.launch(share=True)

